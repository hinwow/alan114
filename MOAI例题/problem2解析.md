

# PyTorch卷积神经网络（CNN）代码详细解析与输出尺寸计算  


## **一、简介**  
本文以一个经典的卷积神经网络（CNN）为例，详细解析其代码结构、各层功能，并**逐步骤推导输出尺寸**（以MNIST数据集的28×28灰度图为输入）。模型包含两个卷积块（卷积层+激活函数+池化层）和一个全连接输出层，适用于图像分类任务（如MNIST的0-9数字分类）。  


## **二、网络结构总览**  
模型结构可概括为：  
```
输入（28×28灰度图） → 卷积层1 → ReLU激活 → 最大池化1 → 卷积层2 → ReLU激活 → 最大池化2 → 展平 → 全连接层 → 输出（10维分类向量）
```  


## **三、代码逐行解析**  
### **3.1 网络初始化（`__init__`方法）**  
```python
import torch
import torch.nn as nn

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        # 第一个卷积块：卷积层 → ReLU → 最大池化
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # 输入通道1，输出通道16，3×3卷积核，padding=1
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(2)  # 2×2最大池化

        # 第二个卷积块：卷积层 → ReLU → 最大池化
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)  # 输入通道16，输出通道32，3×3卷积核，padding=1
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(2)  # 2×2最大池化

        # 全连接输出层：展平后输入 → 10维分类向量
        self.fc = nn.Linear(32 * 7 * 7, 10)  # 输入维度：32通道×7×7尺寸；输出10类
```  


### **3.2 前向传播（`forward`方法）**  
```python
    def forward(self, x):
        # 第一个卷积块
        x = self.conv1(x)   # 输入：(batch_size, 1, 28, 28) → 输出：(batch_size, 16, 28, 28)
        x = self.relu1(x)   # 激活后尺寸不变：(batch_size, 16, 28, 28)
        x = self.pool1(x)   # 池化后尺寸减半：(batch_size, 16, 14, 14)

        # 第二个卷积块
        x = self.conv2(x)   # 输入：(batch_size, 16, 14, 14) → 输出：(batch_size, 32, 14, 14)
        x = self.relu2(x)   # 激活后尺寸不变：(batch_size, 32, 14, 14)
        x = self.pool2(x)   # 池化后尺寸减半：(batch_size, 32, 7, 7)

        # 展平 + 全连接输出
        x = x.view(x.size(0), -1)  # 展平为一维向量：(batch_size, 32×7×7) = (batch_size, 1568)
        x = self.fc(x)             # 输出分类向量：(batch_size, 10)
        return x
```  


## **四、各层详细说明与输出尺寸计算**  
### **4.1 输入数据格式**  
假设输入为MNIST数据集的28×28灰度图，批量大小（`batch_size`）为64，则输入张量形状为：  
\[ \text{输入} = (64,\ 1,\ 28,\ 28) \]  
- 第1维：`batch_size=64`（每次处理64张图像）。  
- 第2维：`in_channels=1`（灰度图，单通道）。  
- 第3-4维：`height=28`, `width=28`（图像尺寸）。  


### **4.2 第一个卷积块（`conv1 → relu1 → pool1`）**  
#### **4.2.1 卷积层1（`conv1`）**  
- **参数**：`nn.Conv2d(1, 16, kernel_size=3, padding=1)`。  
- **作用**：提取图像局部特征（如边缘、线条）。  
- **输出尺寸计算**：  
  卷积层输出尺寸公式：  
  \[ H_{\text{out}} = \frac{H_{\text{in}} + 2 \times \text{padding} - \text{kernel\_size}}{\text{stride}} + 1 \]  
  \[ W_{\text{out}} = \frac{W_{\text{in}} + 2 \times \text{padding} - \text{kernel\_size}}{\text{stride}} + 1 \]  
  - `H_in=28`, `W_in=28`（输入图像高度/宽度）。  
  - `kernel_size=3`, `padding=1`, `stride=1`（默认步长为1）。  
  - 代入公式：  
    \[ H_{\text{out}} = \frac{28 + 2 \times 1 - 3}{1} + 1 = 28 \]  
    \[ W_{\text{out}} = \frac{28 + 2 \times 1 - 3}{1} + 1 = 28 \]  
  - **输出形状**：`(64,\ 16,\ 28,\ 28)`（16个卷积核，每个输出28×28的特征图）。  


#### **4.2.2 激活函数（`relu1`）**  
- **参数**：`nn.ReLU()`。  
- **作用**：引入非线性，公式为 \( \text{ReLU}(x) = \max(0,\ x) \)。  
- **输出尺寸**：与输入相同（仅修改像素值，不改变空间尺寸），即 `(64,\ 16,\ 28,\ 28)`。  


#### **4.2.3 最大池化层1（`pool1`）**  
- **参数**：`nn.MaxPool2d(2)`（核大小2×2，默认步长=核大小=2）。  
- **作用**：降低特征图空间维度（宽/高），减少计算量，增强平移不变性（局部特征位置变化不影响输出）。  
- **输出尺寸计算**：  
  池化层输出尺寸公式（步长=stride=2）：  
  \[ H_{\text{out}} = \frac{H_{\text{in}} - \text{kernel\_size}}{\text{stride}} + 1 \]  
  \[ W_{\text{out}} = \frac{W_{\text{in}} - \text{kernel\_size}}{\text{stride}} + 1 \]  
  - `H_in=28`, `W_in=28`, `kernel_size=2`, `stride=2`。  
  - 代入公式：  
    \[ H_{\text{out}} = \frac{28 - 2}{2} + 1 = 14 \]  
    \[ W_{\text{out}} = \frac{28 - 2}{2} + 1 = 14 \]  
  - **输出形状**：`(64,\ 16,\ 14,\ 14)`（空间尺寸减半）。  


### **4.3 第二个卷积块（`conv2 → relu2 → pool2`）**  
#### **4.3.1 卷积层2（`conv2`）**  
- **参数**：`nn.Conv2d(16, 32, kernel_size=3, padding=1)`。  
- **作用**：提取更抽象的特征（如纹理、局部结构组合）。  
- **输出尺寸计算**：  
  输入特征图尺寸为 `(64,\ 16,\ 14,\ 14)`（16通道，14×14空间尺寸）。  
  代入卷积层公式（`kernel_size=3`, `padding=1`, `stride=1`）：  
  \[ H_{\text{out}} = \frac{14 + 2 \times 1 - 3}{1} + 1 = 14 \]  
  \[ W_{\text{out}} = \frac{14 + 2 \times 1 - 3}{1} + 1 = 14 \]  
  - **输出形状**：`(64,\ 32,\ 14,\ 14)`（32个卷积核，每个输出14×14的特征图）。  


#### **4.3.2 激活函数（`relu2`）**  
- **作用**：与`relu1`相同，引入非线性。  
- **输出尺寸**：`(64,\ 32,\ 14,\ 14)`（空间尺寸不变）。  


#### **4.3.3 最大池化层2（`pool2`）**  
- **参数**：`nn.MaxPool2d(2)`（核大小2×2，步长=2）。  
- **输出尺寸计算**：  
  输入特征图尺寸为 `(64,\ 32,\ 14,\ 14)`。  
  代入池化层公式：  
  \[ H_{\text{out}} = \frac{14 - 2}{2} + 1 = 7 \]  
  \[ W_{\text{out}} = \frac{14 - 2}{2} + 1 = 7 \]  
  - **输出形状**：`(64,\ 32,\ 7,\ 7)`（空间尺寸再次减半）。  


### **4.4 全连接层（`fc`）**  
#### **4.4.1 展平操作（`x.view(...)`）**  
- **作用**：将多维特征图展平为一维向量，以便输入全连接层。  
- **展平后维度计算**：  
  池化层2输出形状为 `(64,\ 32,\ 7,\ 7)`，展平后每个样本的特征长度为：  
  \[ 32\ (\text{通道数}) \times 7\ (\text{高度}) \times 7\ (\text{宽度}) = 1568 \]  
  - **展平后形状**：`(64,\ 1568)`（64个样本，每个样本1568维特征）。  


#### **4.4.2 全连接层（`fc`）**  
- **参数**：`nn.Linear(32×7×7,\ 10)`。  
- **作用**：整合全局特征，输出分类概率（10维向量对应0-9数字）。  
- **输出形状**：`(64,\ 10)`（64个样本，每个样本10维分类向量）。  


## **五、模型实例化与设备分配**  
```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # 检查GPU可用性
model = CNN().to(device)  # 将模型参数加载到GPU（或CPU）
print(model)  # 打印模型结构
```  


## **六、关键细节总结**  
| 组件               | 功能                                                                 | 参数说明                                                                 |
|--------------------|----------------------------------------------------------------------|--------------------------------------------------------------------------|
| `Conv2d`           | 提取局部特征（边缘、纹理等）                                         | `in_channels`：输入通道数；`out_channels`：卷积核数量；`kernel_size`：核大小；`padding`：保持尺寸 |
| `ReLU`             | 引入非线性，避免深层网络退化为线性模型                               | 无参数，逐元素计算 \( \max(0,\ x) \)                                    |
| `MaxPool2d`        | 降低空间维度（宽/高），减少计算量，增强平移不变性                     | `kernel_size`：池化核大小（步长默认等于核大小）                          |
| `Linear`           | 整合全局特征，输出分类结果                                           | `in_features`：输入向量长度；`out_features`：输出类别数（如10）          |


## **七、扩展说明**  
### **7.1 输入通道数调整**  
若输入为RGB图像（3通道），需将`conv1`的`in_channels`改为3：  
```python
self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # RGB图像输入通道为3
```  


### **7.2 输出类别数调整**  
若任务为其他分类（如CIFAR-100的100类），需调整全连接层的输出维度：  
```python
self.fc = nn.Linear(32 * 7 * 7, 100)  # 输出100维向量对应100类
```  


### **7.3 输入尺寸非28×28的情况**  
若输入图像尺寸为32×32（如CIFAR-10），两次池化后的尺寸为8×8（32→16→8），全连接层输入维度需调整为：  
```python
self.fc = nn.Linear(32 * 8 * 8, 10)  # 32通道×8×8尺寸
```  


## **八、总结**  
该模型通过“卷积→激活→池化”的经典结构逐步提取图像特征，最终通过全连接层输出分类结果。通过详细的输出尺寸计算，可清晰理解特征在网络中的流动过程，为调试和优化模型（如调整卷积核数量、池化策略）提供依据。