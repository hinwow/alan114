{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":101526,"databundleVersionId":12239234,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, PolynomialFeatures  # 新增PolynomialFeatures\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline  # 重点使用Pipeline整合流程\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\n\n# 数据加载与预处理（保持原逻辑）\ntrain_data = pd.read_csv('/kaggle/input/moai/Iris_train_data.csv')\ntest_data = pd.read_csv('/kaggle/input/moai/Iris_test_data.csv')\nlabel_encoder = preprocessing.LabelEncoder()\ntrain_data['Species'] = label_encoder.fit_transform(train_data['Species'])\nX_train = train_data.drop(['Species', 'Id'], axis=1)\ny_train = train_data.loc[:, 'Species']\nX_test = test_data.drop(['Id'], axis=1)\n\n# 构建二阶逻辑回归流水线：多项式特征生成 -> 标准化 -> 逻辑回归\npipeline = Pipeline([\n    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # 二阶多项式特征（无截距项）\n    ('scaler', StandardScaler()),  # 标准化（注意：多项式特征后再标准化更合理）\n    ('classifier', LogisticRegression(penalty='l2', C=1.0, max_iter=5000))  # 增加迭代次数防止不收敛\n])\n\n# 交叉验证评估（与原逻辑一致，但流程更安全）\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='accuracy')\n\nprint(f\"各折准确率: {scores}\")\nprint(f\"平均准确率: {scores.mean():.4f}（标准差: {scores.std():.4f}）\")\n\n# 如果需要训练最终模型并预测测试集（可选）\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_test)  # 测试集预测（自动应用多项式+标准化）\nres_df = pd.DataFrame({'Id':test_data['Id'], 'Species': label_encoder.inverse_transform(y_pred)})\nres_df.to_csv('/kaggle/working/aad.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T18:36:56.873060Z","iopub.execute_input":"2025-05-10T18:36:56.873405Z","iopub.status.idle":"2025-05-10T18:37:02.317136Z","shell.execute_reply.started":"2025-05-10T18:36:56.873353Z","shell.execute_reply":"2025-05-10T18:37:02.316344Z"}},"outputs":[{"name":"stdout","text":"各折准确率: [0.91666667 1.         0.95833333 1.         0.875     ]\n平均准确率: 0.9500（标准差: 0.0486）\n","output_type":"stream"}],"execution_count":1}]}