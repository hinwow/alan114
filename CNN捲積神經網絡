# PyTorch CNN 組件全解析

## 1. 卷積層 (Convolutional Layer)
### `nn.Conv2d` 參數詳解
| 參數             | 類型        | 功能說明                         | 默認值       |
|------------------|-------------|----------------------------------|-------------|
| `in_channels`    | int         | 輸入通道數（如RGB圖像為3）        | 必填        |
| `out_channels`   | int         | 輸出通道數（卷積核數量）           | 必填        |
| `kernel_size`    | int/tuple   | 卷積核尺寸（如3或(3,3)）          | 必填        |
| `stride`         | int/tuple   | 滑動步長（控制輸出尺寸縮放）       | 1          |
| `padding`        | int/tuple   | 邊緣填充像素數（保持空間維度）     | 0          |
| `padding_mode`   | str         | 填充模式（`zeros`, `reflect`等）  | `'zeros'`  |
| `dilation`       | int/tuple   | 卷積核元素間距（空洞卷積）         | 1          |
| `bias`           | bool        | 是否啟用偏置項                    | `True`     |

```python
# 示例：3輸入通道 → 8輸出通道，3x3卷積核，填充1像素
self.conv = nn.Conv2d(3, 8, kernel_size=3, padding=1)

2. 池化層 (Pooling Layer)
nn.MaxPool2d 最大池化
參數	類型	功能說明	默認值
kernel_size	int/tuple	池化窗口尺寸（如2或(2,2)）	必填
stride	int/tuple	滑動步長（未指定時等同kernel_size）	None
padding	int/tuple	邊緣填充像素數	0
dilation	int/tuple	窗口元素間距	1
python
# 示例：2x2池化窗口，步長2
self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

3. 全連接層 (Fully Connected Layer)
nn.Linear 線性變換
參數	類型	功能說明	默認值
in_features	int	輸入特徵維度（展平後總數）	必填
out_features	int	輸出特徵維度（如分類數）	必填
bias	bool	是否啟用偏置項	True
python
# 示例：將16x56x56特徵展平後映射到3類
self.fc = nn.Linear(16*56*56, 3)

4. 激活函數 (Activation Functions)
F.relu 非線性激活


使用時機: 通常在卷積/全連接層後立即使用

5. 數據預處理流程 (Transforms)
torchvision.transforms 組合
方法	參數說明
Resize((H, W))	強制縮放圖像至固定尺寸（如224x224）
RandomAffine	degrees（旋轉範圍）, translate（平移比例）, scale（縮放範圍）
RandomHorizontalFlip	以50%概率水平翻轉圖像
ToTensor()	轉換為PyTorch張量（範圍[0,1]，自動處理HWC→CHW格式）
Normalize()	基於均值與標準差的標準化（如ImageNet參數）
# 完整訓練集預處理流程
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomAffine(degrees=10, shear=5, scale=(0.8, 1.2)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

6. 數據加載器 (Data Loader)
DataLoader 關鍵參數
參數	類型	功能說明	推薦值
dataset	Dataset	加載的數據集對象	必填
batch_size	int	單批次樣本數（根據GPU顯存調整）	32/64/128
shuffle	bool	是否打亂數據（僅訓練集需True）	True
num_workers	int	並行加載進程數（加速數據讀取）	4-8
pin_memory	bool	鎖頁內存（GPU訓練時建議啟用）	True
# 驗證集加載示例
val_loader = DataLoader(
    dataset=val_dataset,
    batch_size=32,
    shuffle=False,  # 驗證集不需打亂
    num_workers=4,
    pin_memory=True
)

7. 損失函數與優化器
nn.CrossEntropyLoss 多分類損失
輸入要求: 模型直接輸出logits（無需手動Softmax）

內部機制: 自動結合Softmax與負對數似然損失（NLLLoss）

python
criterion = nn.CrossEntropyLoss()
optim.Adam 自適應優化器
參數	類型	功能說明	典型值
params	iterable	模型參數（model.parameters()）	必填
lr	float	初始學習率（需實驗調整）	0.001~0.0001
betas	tuple	一階/二階動量衰減係數	(0.9, 0.999)
weight_decay	float	L2正則化強度（防過擬合）	1e-4

8. 模型訓練模板
python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CNN().to(device)

for epoch in range(num_epochs):
    # 訓練模式
    model.train()
    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)
        
        # 前向傳播
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # 反向傳播與梯度更新
        optimizer.zero_grad()  # 清除歷史梯度
        loss.backward()        # 自動微分計算
        optimizer.step()       # 參數更新
    
    # 驗證模式
    model.eval()
    with torch.no_grad():
        total_correct = 0
        for images, labels in val_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            total_correct += (preds == labels).sum().item()
        
        val_acc = total_correct / len(val_dataset)
        print(f"Epoch {epoch+1}, Val Acc: {val_acc:.4f}")

9. 高級技巧與注意事項
梯度裁剪：防止梯度爆炸

python
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
學習率調度：動態調整學習率

python
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)
scheduler.step()  # 在每個epoch後調用
早停機制：監控驗證集性能，防止過擬合

python
if val_acc > best_acc:
    best_acc = val_acc
    torch.save(model.state_dict(), 'best_model.pth')
混合精度訓練：加速訓練並減少顯存消耗

python
scaler = torch.cuda.amp.GradScaler()
with torch.cuda.amp.autocast():
    outputs = model(images)
    loss = criterion(outputs, labels)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
模型參數初始化：

python
# He初始化（適用ReLU）
torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')
