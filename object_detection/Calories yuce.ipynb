{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91716,"databundleVersionId":11893428,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:35:38.350634Z","iopub.execute_input":"2025-05-10T08:35:38.350889Z","iopub.status.idle":"2025-05-10T08:35:40.611853Z","shell.execute_reply.started":"2025-05-10T08:35:38.350867Z","shell.execute_reply":"2025-05-10T08:35:40.610862Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e5/sample_submission.csv\n/kaggle/input/playground-series-s5e5/train.csv\n/kaggle/input/playground-series-s5e5/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # 数据可视化\nimport seaborn as sns        # 高级可视化工具\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV  # 数据集划分和超参数搜索\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder    # 数据预处理\nfrom sklearn.compose import ColumnTransformer      # 多列不同预处理组合\nfrom sklearn.pipeline import Pipeline              # 流水线化处理流程\nfrom sklearn.ensemble import RandomForestClassifier  # 随机森林分类模型\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve \nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import (\n    mean_squared_error,          # 均方误差（MSE），越小越好\n    r2_score                     # R²分数，越接近1越好\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:35:40.614135Z","iopub.execute_input":"2025-05-10T08:35:40.614521Z","iopub.status.idle":"2025-05-10T08:35:48.816831Z","shell.execute_reply.started":"2025-05-10T08:35:40.614499Z","shell.execute_reply":"2025-05-10T08:35:48.815910Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_data=pd.read_csv('/kaggle/input/playground-series-s5e5/train.csv')\ntest_data=pd.read_csv('/kaggle/input/playground-series-s5e5/train.csv')\na = preprocessing.LabelEncoder()\ntrain_data['Sex']=a.fit_transform(train_data['Sex'])\ntest_data['Sex']=a.fit_transform(test_data['Sex'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:35:48.821591Z","iopub.execute_input":"2025-05-10T08:35:48.821909Z","iopub.status.idle":"2025-05-10T08:35:50.630963Z","shell.execute_reply.started":"2025-05-10T08:35:48.821878Z","shell.execute_reply":"2025-05-10T08:35:50.630059Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_X=train_data.drop(['id','Height','Body_Temp','Calories'],axis=1)\ntest_X=test_data.drop(['id','Height','Body_Temp','Calories'],axis=1)\ntrain_y=train_data.loc[:,'Calories']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:35:50.632211Z","iopub.execute_input":"2025-05-10T08:35:50.632463Z","iopub.status.idle":"2025-05-10T08:35:50.663985Z","shell.execute_reply.started":"2025-05-10T08:35:50.632442Z","shell.execute_reply":"2025-05-10T08:35:50.663032Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"    X_tr, X_val, y_tr, y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42)\n    scaler = StandardScaler()               # 初始化标准化器\n    X_tr_scaled = scaler.fit_transform(X_tr)  # 在训练集上拟合标准化参数并转换\n    X_val_scaled = scaler.transform(X_val)  # 验证集转换（使用训练集的参数）\n    X_test_scaled = scaler.transform(test_X)  # 测试集转换","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:35:50.665091Z","iopub.execute_input":"2025-05-10T08:35:50.665495Z","iopub.status.idle":"2025-05-10T08:35:50.945485Z","shell.execute_reply.started":"2025-05-10T08:35:50.665467Z","shell.execute_reply":"2025-05-10T08:35:50.944517Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"    models = [\n        ('LinearRegression', LinearRegression()),  # 线性回归（无正则化）\n        ('Ridge', Ridge(alpha=1.0)),                # 岭回归（alpha=1.0）\n        ('Lasso', Lasso(alpha=0.1)),                # Lasso回归（alpha=0.1）\n        ('RandomForest', RandomForestRegressor(n_estimators=200, random_state=42)),  # 随机森林（200棵树）\n        ('XGBoost', XGBRegressor(n_estimators=200, random_state=42, verbosity=0)),\n        ('LightGBM', LGBMRegressor(n_estimators=200, random_state=42))\n    ]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:35:50.947551Z","iopub.execute_input":"2025-05-10T08:35:50.948096Z","iopub.status.idle":"2025-05-10T08:35:50.953058Z","shell.execute_reply.started":"2025-05-10T08:35:50.948074Z","shell.execute_reply":"2025-05-10T08:35:50.952295Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"best_sc=-np.inf\nbest_model=None\nbest_name=\"\"\nres=[]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:35:50.954346Z","iopub.execute_input":"2025-05-10T08:35:50.954665Z","iopub.status.idle":"2025-05-10T08:35:50.973460Z","shell.execute_reply.started":"2025-05-10T08:35:50.954642Z","shell.execute_reply":"2025-05-10T08:35:50.972416Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"    for name, model in models:\n        model.fit(X_tr_scaled, y_tr)                   # 训练模型\n        val_pred = model.predict(X_val_scaled)         # 预测验证集\n        r2 = r2_score(y_val, val_pred)                # 计算R²\n        mse = mean_squared_error(y_val, val_pred)      # 计算MSE\n        res.append((name,r2,mse))                # 记录结果\n        if r2 > best_sc:                            # 更新最优模型\n            best_sc = r2\n            best_model = model\n            best_name = name\n        print(f\"\\n最优模型：{best_name}，验证集R2: {best_sc:.4f}\")  # 输出最优模型\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:35:50.975041Z","iopub.execute_input":"2025-05-10T08:35:50.975354Z","iopub.status.idle":"2025-05-10T08:41:24.891149Z","shell.execute_reply.started":"2025-05-10T08:35:50.975328Z","shell.execute_reply":"2025-05-10T08:41:24.890013Z"}},"outputs":[{"name":"stdout","text":"\n最优模型：LinearRegression，验证集R2: 0.9589\n\n最优模型：LinearRegression，验证集R2: 0.9589\n\n最优模型：LinearRegression，验证集R2: 0.9589\n\n最优模型：RandomForest，验证集R2: 0.9960\n\n最优模型：XGBoost，验证集R2: 0.9965\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008185 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 236\n[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 5\n[LightGBM] [Info] Start training from score 88.298465\n\n最优模型：XGBoost，验证集R2: 0.9965\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"    test_pred = best_model.predict(X_test_scaled)       \n    res_df = pd.DataFrame({'id':test_data['id'], 'Calories': test_pred})  \n    res_df.to_csv('/kaggle/working/aaa.csv', index=False)      \n    print(\"最优模型预测结果已保存至 /kaggle/working/aaa.csv\")   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:41:24.892321Z","iopub.execute_input":"2025-05-10T08:41:24.892683Z","iopub.status.idle":"2025-05-10T08:41:27.478559Z","shell.execute_reply.started":"2025-05-10T08:41:24.892661Z","shell.execute_reply":"2025-05-10T08:41:27.477690Z"}},"outputs":[{"name":"stdout","text":"最优模型预测结果已保存至 /kaggle/working/aaa.csv\n","output_type":"stream"}],"execution_count":9}]}