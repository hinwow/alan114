{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":100823,"databundleVersionId":12113835,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 导入必要的库\nimport pandas as pd          # 数据操作库，核心函数：pd.read_csv()读取CSV文件\nimport numpy as np           # 数值计算库，提供多维数组支持\nimport matplotlib.pyplot as plt  # 绘图库，plt.plot()用于绘制图表\nimport seaborn as sns        # 高级可视化库，sns.heatmap()绘制热力图\nfrom sklearn.model_selection import (\n    train_test_split,        # 数据集划分函数，参数：test_size, random_state, stratify\n    GridSearchCV             # 超参数网格搜索类，参数：estimator, param_grid, cv, scoring\n)\nfrom sklearn.preprocessing import (\n    StandardScaler,          # 数值标准化（均值0，方差1），用于缩放特征\n    OrdinalEncoder           # 分类特征编码，将类别标签转为整数（例如性别转0/1）\n)\nfrom sklearn.compose import ColumnTransformer  # 多列不同预处理的组合工具，参数：transformers, remainder\nfrom sklearn.pipeline import Pipeline          # 流水线化处理流程，参数：steps\nfrom sklearn.ensemble import RandomForestClassifier  # 随机森林分类器，参数：n_estimators, max_depth等\nfrom sklearn.metrics import (                  # 模型评估指标\n    accuracy_score,          # 准确率 = (TP+TN)/(TP+FP+TN+FN)\n    precision_score,         # 精确率 = TP/(TP+FP)\n    recall_score,            # 召回率 = TP/(TP+FN)\n    f1_score,                # F1 = 2*(Precision*Recall)/(Precision+Recall)\n    roc_auc_score,           # ROC曲线下面积，衡量分类器整体性能\n    roc_curve                # 计算ROC曲线的真阳性率和假阳性率\n)\n\n# 加载数据\n# pd.read_csv()参数说明：\n# - filepath: 文件路径（字符串）\n# - sep: 分隔符（默认','），例如读取TSV文件需指定sep='\\t'\n# - header: 指定列名所在行（默认0，即第一行）\ndf = pd.read_csv('/kaggle/input/houkong-moai/customer_churn.csv')  # 读取客户流失数据集\n\n# 定义预处理流水线\n# ColumnTransformer参数说明：\n# - transformers: 预处理步骤列表，每个元素是元组（名称, 转换器, 列）\n# - remainder: 未被处理的列处理方式（'passthrough'表示保留原数据）\npreprocessor = ColumnTransformer(\n    transformers=[\n        # 对数值列标准化处理\n        # - 'num': 自定义步骤名称\n        # - StandardScaler(): 转换器对象（标准化：均值=0，标准差=1）\n        # - ['age', ...]: 要处理的数值列列表\n        ('num', StandardScaler(), ['age', 'subscription_length', 'monthly_bill', 'total_usage', 'service_complaints']),\n        \n        # 对分类列编码\n        # - 'cat': 步骤名称\n        # - OrdinalEncoder(): 将性别（如Male/Female）转为0/1\n        # - ['gender']: 分类列名列表\n        ('cat', OrdinalEncoder(), ['gender'])\n    ],\n    remainder='passthrough'  # 其他列（若有）直接保留，不处理\n)\n\n# 定义特征矩阵和标签\n# df.drop()参数说明：\n# - labels: 要删除的列名列表（['customer_id', 'churn']）\n# - axis=1: 按列删除（axis=0为行）\nX = df.drop(['customer_id', 'churn'], axis=1)  # 特征矩阵（移除ID和标签列）\ny = df['churn']  # 标签列（客户是否流失，0/1）\n\n# 划分训练集和测试集\n# train_test_split()参数说明：\n# - test_size=0.2: 测试集占比20%\n# - random_state=42: 固定随机种子，确保结果可复现\n# - stratify=y: 按标签分层抽样，保持训练集和测试集的流失比例一致\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    random_state=42, \n    stratify=y\n)\n\n# 创建模型流水线\n# Pipeline参数说明：\n# - steps: 处理步骤列表，按顺序执行\n# - ('preprocessor', preprocessor): 第一步应用预处理\n# - ('classifier', RandomForestClassifier()): 第二步使用随机森林分类器\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier())\n])\n\n# 定义超参数网格\n# param_grid结构：\n# - 键：参数名（格式为\"步骤名__参数名\"）\n# - 值：候选参数值列表\nparam_grid = {\n    'classifier__n_estimators': [100, 200],      # 随机森林中树的数量（100或200）\n    'classifier__max_depth': [None, 10],         # 树的最大深度（None表示不限制，10表示最多10层）\n    'classifier__min_samples_split': [2, 5]      # 节点分裂所需最小样本数（2或5）\n}\n\n# 执行网格搜索\n# GridSearchCV参数说明：\n# - estimator=pipeline: 要优化的模型流程\n# - param_grid=param_grid: 超参数候选值网格\n# - cv=3: 3折交叉验证（训练集分成3份，2份训练，1份验证）\n# - scoring='roc_auc': 以ROC AUC作为评估指标（适用于二分类不平衡数据）\ngrid_search = GridSearchCV(\n    pipeline, \n    param_grid, \n    cv=3, \n    scoring='roc_auc'\n)\ngrid_search.fit(X_train, y_train)  # 在训练集上拟合模型并搜索最优参数\n\n# 获取最优模型\nbest_model = grid_search.best_estimator_  # best_estimator_属性返回最优参数组合的模型\n\n# 加载测试数据（需替换为真实测试集路径）\ntest_data = pd.read_csv('/kaggle/input/houkong-moai/customer_churn.csv')  # 假设测试集结构与训练集相同\n\n# 生成预测结果\n# best_model.predict()参数说明：\n# - 输入特征矩阵（需与训练集结构一致，移除ID和标签列）\npredictions = best_model.predict(test_data.drop(['customer_id', 'churn'], axis=1))\n\n# 创建提交文件\n# pd.DataFrame()参数说明：\n# - data: 字典格式，列名为'customer_id'和'churn'\n# - columns: 指定输出列顺序\nsubmission = pd.DataFrame({\n    'customer_id': test_data['customer_id'],  # 客户ID列\n    'churn': predictions                      # 预测的流失标签（0/1）\n})\n\n# 保存为CSV文件\n# to_csv()参数说明：\n# - path_or_buf='submission.csv': 输出文件路径\n# - index=False: 不保存行索引\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"提交文件已生成！\")  # 输出提示信息","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#代码行\t                      函数/类\t               关键参数\t                参数含义\n#pd.read_csv(...)\t          pandas.read_csv\t       filepath, sep, header\t文件路径、分隔符、列名所在行\n#ColumnTransformer(...)\t      ColumnTransformer\t       transformers, remainder\t预处理步骤组合、未处理列的保留方式\n#train_test_split(...)\t      train_test_split\t       test_size, stratify\t    测试集比例、按标签分层抽样\n#Pipeline(...)\t              Pipeline\t               steps\t                流水线步骤列表（名称, 对象）\n#GridSearchCV(...)\t          GridSearchCV\t           param_grid, scoring\t    超参数候选值网格、评估指标\n#RandomForestClassifier(...)  RandomForestClassifier   n_estimators, max_depth\t决策树数量、树的最大深度\n#submission.to_csv(...)\t      DataFrame.to_csv\t       index\t                是否保存行索引（设为False避免多余列）\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}